name: Continuous Exploit Scraper

on:
  schedule:
    # Runs every 6 hours to stay ahead
    - cron: "0 */6 * * *"
  # Allows manual triggers from the Actions tab
  workflow_dispatch:

jobs:
  scrape_and_aggregate:
    runs-on: ubuntu-latest

    # We need permission to push the parsed JSON arrays back to the repo
    permissions:
      contents: write

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Build and Execute Scraper Engines
        env:
          GITHUB_TOKEN: ${{ secrets.SYNC_TOKEN }}
        run: |
          go build cvemapping.go
          go build nvd_scraper.go

          YEAR=$(date +%Y)
          LAST_YEAR=$(date -d "last year" +%Y)

          echo "Firing Main Engine..."
          echo "CVE-$YEAR-" | ./cvemapping -github-token "$GITHUB_TOKEN" -export-json -year "$YEAR"
          echo "CVE-$LAST_YEAR-" | ./cvemapping -github-token "$GITHUB_TOKEN" -export-json -year "$LAST_YEAR"

          echo "Firing NVD Engine..."
          ./nvd_scraper

      - name: Move Data to Web Directory
        run: |
          mkdir -p web/data
          # Copy JSON files into the frontend directory
          cp data/*.json web/data/ 2>/dev/null || true

      - name: Commit & Push New Datasets
        run: |
          git config --global user.name "Nikhil Yadav (Bot)"
          git config --global user.email "yadavnikhil17102004@gmail.com"
          git add data/ web/data/ || true

          # Only commit if there are changes
          if ! git diff-index --quiet HEAD; then
            git commit -m "chore(data): Automated upstream exploit sync [skip ci]"
            git push
          else
            echo "No new CVEs discovered. Skipping push."
          fi
